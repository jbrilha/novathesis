%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter2.tex
%% NOVA thesis document file
%%
%% Chapter with the template manual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter2.tex}%

\chapter{Related Work}
\label{cha:related_work}

\glsresetall

\todo{mencionar MQTT, CoAP em detalhe somewhere}

Internet of Things (IoT) and home automation (domotics) systems share the same
technological building blocks (wireless sensors, embedded devices, network
communication) but diverge significantly in their operational focus and
architectures:

\begin{description}
    \item \textbf{IoT systems} typically focus on \textbf{data collection and
        monitoring}, by streaming sensor readings to centralized platforms for
        analysis and processing, with control functions often being a secondary
        concern.
    \item \textbf{Domotics systems} instead prioritize \textbf{real-time
        control and actuation} over physical spaces, where responsiveness and
        local autonomy are paramount for end user experience and privacy.
\end{description}

This distinction gains additional relevance when focusing on resilience
requirements: while IoT deployments may tolerate delayed data aggregation
and/or temporary connectivity issues in monitoring scenarios, domotics
applications (such as emergency lighting control or HVAC management) demand
immediate local response regardless of network conditions.

Both domains, however, suffer from a common vulnerability when confronted with
infrastructure failures during disasters: their predominantly cloud-centric
architectures collapse precisely when autonomous operation becomes
indispensable.\\

The challenges faced by disaster-resilient IoT systems span multiple dimensions:
\begin{description}
    \item \textbf{Infrastructure failures} eliminate access points that devices
        depend on for coordination;
    \item \textbf{Intermittent connectivity} creates network partitions where
        subgroups of devices must operate autonomously without global state
        synchronization;
    \item \textbf{Resource constraints} limit the computational, memory and
        energy budgets available for implementing sophisticated resilience
        mechanisms in embedded platforms.
\end{description}

\textbf{MicroBabel} addresses these concerns through a decentralized approach
that aims to eliminate the dependency on centralized coordination, continuous
connectivity and cloud infrastructure.

Rather than treating infrastructure failures as an exceptional condition
requiring failover mechanisms, our architecture focuses on autonomous
peer-to-peer connectivity as the baseline mode of operation, with
infrastructure integration as an added benefit when available, rather than a
hard dependency.

This approach means rethinking multiple aspects of traditional IoT systems
design: from multi-protocol communication strategies that adapt to the
available mediums and device resources without centralized control, to
gossip-based synchronization mechanisms that achieve coordination through local
interactions, to lightweight data compression techniques to make the most out
of the limited storage and battery available in each device.

The following sections briefly cover related work across five areas that
collectively enable autonomous operation: (Section \ref{sec:multi-proto})
multi-protocol communication and adaptive selection based on QoS and device
capabilities; (Section~\ref{sec:p2p_mesh}) peer-to-peer mesh networking and
topology management for autonomous network formation without coordinator
dependencies; (Section~\ref{sec:decentr_sync}) decentralized synchronization
mechanisms for coordinating multi-protocol communication without master nodes;
(Section~\ref{sec:data_compression}) lightweight data compression and energy
optimization techniques to extend autonomous operation duration and device
lifetime; and (Section~\ref{sec:sec_priv}) security and privacy mechanisms that
enable systems to maintain secure communication after infrastructure failures.

For each area, we examine how existing approaches handle (or fail to handle)
infrastructure failure scenarios, identify architectural assumptions that
conflict with disaster-resilient requirements, and position
\textbf{MicroBabel}'s contributions relative to the current state of the art.

\section{Multi-Protocol Communication and Adaptive Protocol Selection}
\label{sec:multi-proto}

Single-protocol (i.e. Wi-Fi only, BLE only, LoRa only, etc.) communication
architectures are susceptible to a fundamental vulnerability: if their chosen
medium becomes unavailable or inefficient due to interference, range
limitations, or infrastructure failures, the entire system loses connectivity
and most times ceases to function altogether.

This becomes especially grave in disaster scenarios where communication
conditions change unpredictably due to factors such as RF interference from debris,
obstacles blocking line-of-sight propagation, or damage to access points.

Existing approaches to multi-protocol IoT systems can be placed in three
categories: multi-channel resilience architectures that orchestrate
communication technologies for emergency scenarios; implementations that show
the feasibility of protocol heterogeneity on embedded platforms; and adaptive
selection frameworks that switch protocols based on runtime conditions.

\subsection{Multi-Channel Resilience Architectures}
\label{subsec:multi-channel}

Several disaster-focused systems explicitly address infrastructure failures
through protocol diversity.

The AWCT (Always Connected Things) framework~\cite{awct} orchestrates LPWAN
(LoRa/LoRaWAN) with ad-hoc networks (Bluetooth and Wi-Fi) specifically for
standby emergency communication. Their architecture adds three modules to
standard IoT devices (Raspberry Pi boards, in their test case): a battery module
for power management, a power interrupt handler that triggers emergency mode
when the power grid fails, and an ad-hoc bridge that forwards packets between
the Bluetooth, Wi-Fi and LPWAN interfaces.

The system leverages dense IoT device deployment to provide emergency coverage,
demonstrating that existing infrastructure can still serve a purpose during
scenarios where the main power grid suffers issues.

However, AWCT's reliance on centralized LoRaWAN gateways for Internet
connectivity creates a single point of failure when those gateways become
unreachable.\\

A more comprehensive heterogeneous approach is presented
in~\cite{heterogeneous-disaster}, which integrates HF radio (NVIS), satellite
links, wireless sensor networks (WSNs), and delay-tolerant networking (DTN)
with mobile drones for disaster monitoring. Their system uses RPL (Routing
Protocol for Low-Power and Lossy Networks)~\cite{rfc6550} with three separate
instances to differentiate traffic by priority: human data (voice/text via
Bluetooth) receives the highest priority, followed by drone-collected data and
finally sensor data.

The NVIS backhaul provides 250 km coverage radius without line-of-sight
requirements, offering a cost-effective alternative to satellite
communications.

While demonstrating successful real-world validation in Antarctica and urban
deployments, the architecture's core NVIS topology with centralized coordination
contrasts fully distributed operational requirements. Furthermore, their WSN
layer requires a minimum 20-second sending interval to maintain acceptable
packet loss rates at 10 hops, which highlights throughput limitations of
single-channel tree topologies.\\

Security-focused multi-channel approaches like MCSC-WoT~\cite{mcsc-wot} combine
AES encryption with dynamic channel hopping across 2.4 GHz Wi-Fi channels to
defend against jamming and eavesdropping attacks. Their lightweight
synchronization mechanism minimizes energy consumption while maintaining
security through Frequency Hop Spread Spectrum (FHSS) patterns generated via
PRNG. Nodes that lose synchronization can rejoin by hopping to random channels
and waiting for the next synchronization signal.

However, the system depends on a master node broadcasting synchronization
signals and uses an initial PRNG seed shared among all nodes, raising questions
about scalability and seed distribution mechanisms -- particularly how new
nodes can acquire seeds if deployed to a network at a later time.

\subsection{Protocol Heterogeneity on Embedded Platforms}
\label{subsec:proto-het}

The work presented in~\cite{multiproto_gateway} shows the technical feasibility
of multi-protocol operation on commodity Wi-Fi/BLE modules by integrating
ESP-NOW, ZigBee, and Modbus protocols on devices from the ESP32 family to
construct multi-hop, tree-based wireless networks.

Their implementation uses BLE advertising beacons for neighbor discovery with
RSSI measurements (for distance estimation), computing parent selection
priorities based on weighted combinations of child count, RSSI values, and hop
count in the network tree of a given node. The system also supports automatic
parent reselection when the current parent becomes unreachable, making it
somewhat resilient to single node failures.

Testing demonstrated successful multi-hop operation up to 5 hops in office
environments, but evaluation was limited to linear network topologies.
Additionally, this architecture relies on a tree topology with master-slave
communication that is centered around a gateway (coordinator) rather than being
a peer-to-peer mesh, creating a single point of failure at the coordinator
node.\\

\todo{encontrar outro paper para inserir aqui}

\subsection{Runtime Adaptive Protocol Selection}
\label{subsec:runtime-adaptive}

A recent approach to protocol adaptation is presented
in~\cite{adaptive2025}, which introduces a closed-loop control system with
four integrated components: a context monitor sampling runtime metrics at 1 Hz,
a decision engine using multi-criteria weighted scoring across six dimensions
(message frequency, payload size, network conditions, packet loss rate, energy
budget, QoS requirements), protocol adapters encapsulating protocol-specific
libraries, and a learning component that adjusts thresholds using EWMA
(Exponentially Weighted Moving Average) for deployment-specific patterns.

Some key aspects of this work include hysteresis control with a threshold band
to prevent oscillation between protocols, and switching cost awareness
requiring benefits to exceed costs by a certain threshold before transitioning.

However, this framework assumes infrastructure availability for protocol
endpoints (MQTT brokers, HTTP servers, CoAP endpoints) and was evaluated only
on laptop platforms using Python libraries rather than embedded C
implementations.

Nevertheless, the evaluation methodology provides valuable insight into the
energy expenditure of these different approaches (further explored in
Section~\ref{subsec:receiver_energy}), and grants useful foundations for more
complex multi-protocol approaches, in particular with the multi-criteria
decision framework and hysteresis control mechanism, but the actual system
cannot operate when infrastructure fails.\\

The MINOS platform~\cite{minos2019} exemplifies the limitations of centralized
multi-protocol approaches. While providing sophisticated multi-protocol support
(CORAL-SDN and Adaptable-RPL) with dynamic protocol deployment and real-time
parameter tuning, the system depends fundamentally on a centralized SDN
controller, MQTT broker, and web server infrastructure. The architecture's
single point of failure means that when the controller becomes unreachable the
entire system loses its adaptive capabilities and reverts to static operation
at best, or complete failure at worst.

\subsection{MicroBabel's Approach}
\label{subsec:microbabel_approach_1}

While existing multi-channel approaches rely on centralized decision-making for
channel selection -- whether through master nodes (MCSC-WoT), SDN controllers
(MINOS), or infrastructure endpoints -- \textbf{MicroBabel} will address these
limitations through decentralized \emph{protocol} selection, extending beyond
single-medium channel hopping.

\todo{nail down a arquitetura primeiro maybe}
The system will employ opportunistic multi-protocol operation (BLE + Wi-Fi +
LoRa + ESP-NOW) wherein devices adaptively select communication mediums based
on factors like message priority, neighbor availability, energy budget, network
conditions and device capabilities. This selection will be performed through
local decision-making informed by information gathered through gossip
protocols, without requiring SDN controllers or infrastructure coordination.

Hysteresis control mechanisms adapted from the Adaptive Protocol Selection
Framework prevent oscillations in these decisions while allowing rapid
response to changing conditions.

Protocol-specific compression strategies account for the different
energy/bandwidth trade-offs across the proposed stack (e.g. aggressive
compression for (relatively) energy-expensive LoRa, lighter compression for
short-range BLE), integrating the receiver energy asymmetry observations into
power management decisions.

Unlike AWCT's LoRaWAN gateway dependency, Heterogeneous IoT's NVIS centralized
backhaul, MCSC-WoT's master-based synchronization, or MINOS's SDN controller
requirement, \textbf{MicroBabel} operates autonomously in a peer-to-peer
manner with no static coordinator dependencies.\todo{again discutir arquitetura}

The multi-protocol capability provides resilience through diversity rather than
optimization through centralized selection: when conditions render one medium
unsuitable, devices autonomously transition to alternatives without requiring
coordinator intervention.

\section{Peer-to-Peer Mesh Networking and Topology Management}
\label{sec:p2p_mesh}

Infrastructure-dependent star topologies in which devices communicate via a
central coordinator or gateway suffer from a similar fate to single-protocol
communication: when that coordinator becomes unavailable or unreachable, the
entire network loses connectivity.

This pattern pervades current IoT deployments, from Wi-Fi access point
dependencies to LoRaWAN gateway requirements, and becomes catastrophic in
disaster scenarios where central coordinators are most likely to fail first.

Peer-to-peer (P2P) mesh architectures address this limitation by distributing
coordination across all participating nodes, thus eliminating single points of
failure. Nonetheless, achieving robust mesh operation requires solving three
interconnected challenges: neighbor discovery and establishment of initial
connectivity, topology maintenance as nodes join/leave a network, and efficient
data routing through multi-hop paths when direct communication becomes
impossible or inefficient.

\subsection{Peer Discovery and Topology Maintenance}
\label{subsec:peer_disc}

As discussed in Section~\ref{subsec:proto-het}, the Multi-Protocol IoT Gateway
implementation~\cite{multiproto_gateway} demonstrates BLE-based neighbor
discovery with RSSI measurements for proximity estimation.

While that work focuses on multi-protocol integration, its topology management
reveals a limitation of its tree-based approach: the system implements
automatic parent reselection when coordinators fail, but the underlying tree
structure imposes that nodes can only communicate through their parent-child
relationships rather than arbitrary peer connections.

This restriction limits route diversity and resilience, creating dependency
chains where a single intermediate node failure can disconnect entire subtrees.\\

A more sophisticated approach to membership management is presented in
HyParView~\cite{hyparview2007}, in which each node maintains two distinct
partial views for scalability: a small active view (size = fanout + 1)
containing nodes with which symmetric links are actively maintained, and a
larger passive view serving as a backup pool of potential neighbors that may be
promoted to the active view if one of its nodes fails.

The active view is managed reactively, such that nodes are added during join
operations and removed upon failure detection, while the passive view is
maintained cyclically through periodic shuffle operations that exchange node
identifiers between peers.

This hybrid strategy enables remarkable resilience, with the system recovering
from 80\% node failures with minimal reliability loss (maintaining ~95\%
reliability) and from 50\% failures in just 1-2 membership cycles, compared to
60+ cycles required by purely cyclic protocols like Cyclon~\cite{cyclon2005}.

HyParView's deterministic flooding approach, by broadcasting messages along the
entire active view graph rather than probabilistic neighbor selection, enables
fast failure detection since every active link is tested at each broadcast. The
symmetric link requirement ensures bidirectionality: if node A can reach node
B, then B can reach A, preventing the formation of one-way communication paths
that complicate routing.

However, HyParView assumes TCP availability for maintaining persistent
connections and using connection failures as implicit failure detectors. This
dependency on full network stack functionality makes direct application to
resource-constrained embedded platforms challenging, though the architectural
principles of hybrid views and shuffle-based passive view maintenance remain
valuable.\\

The heterogeneous disaster IoT architecture discussed in
Section~\ref{subsec:multi-channel} employs RPL for its WSN layer, demonstrating
practical routing in resource-constrained disaster scenarios. 

Their performance analysis reveals considerable trade-offs: convergence time
scales linearly from 7 seconds for 20 nodes to 14.5 seconds for 100 nodes,
while packet loss ratio (PLR) at 10 hops reaches 80\% with a 10-second sending
interval but becomes acceptable at 20-second intervals.

These measurements highlight the throughput limitations imposed by tree
topologies, in that their Instance 1 traffic (human data) must be restricted to
1-hop from the root node to ensure the least possible delay in its delivery,
defeating the purpose of multi-hop mesh for critical communications.

The DTN component using mobile drones as data mules provides an alternative
path for partitioned networks, with a maximum of 20 nodes per DODAG
(destination-oriented directed acyclic graph) to maintain acceptable
convergence times during emergency situations, but this approach trades latency
for eventual delivery rather than real-time mesh routing.

\subsection{Routing in Partitioned and Intermittently Connected Networks}
\label{subsec:routing_parts}

When network partitions prevent end-to-end paths, store-and-forward mechanisms
enable eventual data delivery. The Bundle Protocol~\cite{rfc5050} addresses
delay-tolerant networking through custody-based retransmission and
opportunistic connectivity exploitation. While the protocol specification
predates modern IoT deployments and was not designed specifically for
resource-constrained devices, its core principles inform contemporary DTN
approaches.\\

The framework presented in~\cite{fast2018} implements elastic bandwidth
utilization by dynamically adjusting transmission rates based on available
connectivity, and supports scheduled, predicted, and opportunistic transmission
windows, taking inspiration from the Bundle Protocol. 

Data parcels are compressed, encrypted, and bundled before transmission, with a
load balancer managing concurrent transfer threads to optimize bandwidth usage
during brief connectivity windows.

While their HTTP-based implementation targets cloud-backed IoT deployments, the
core concepts of parceling data, maintaining transmission queues, and
opportunistic forwarding during connectivity windows translate to peer-to-peer
scenarios where aggregation nodes become neighbors in a mesh network.

\subsection{Limitations of Centralized Coordination}
\label{subsec:limitations_centralized}

The work on Resilient Edge-enabled IoT~\cite{resilient2019} addresses
coordinator failures through dynamic leader election and backup mechanisms
within their framework.

Their coordination model divides environments into collaboration areas, with
resource-rich edge devices serving as coordinators that allocate tasks to
workers under their supervision when problems arise. Workers, in turn, are
\emph{active agents} such as robots and IoT devices that reside in a
particular environment, detect problems, and notify their coordinators.

When coordinators fail, the system automatically elects backups through
adaptive decentralized consensus, providing "gentle degradation" during
failures with restoration after recovery. Multiple coordinators operate
independently, eliminating single points of failure within the coordination
model itself.

This architecture depends fundamentally on edge servers running JVM-based SCAFI
middleware (a Scala library) to execute the aggregate programs that specify
coordination behavior, and these heavyweight infrastructure requirements --
both the Java runtime environment and resource-rich edge computing nodes --
conflict with embedded platform constraints and infrastructure-failure
scenarios.\todo{queremos mingle com o Babel... se calhar não entrar por aqui ou tudo bem porque não vamos usar os big-babeis para coordination?}

While the aggregate computing paradigm separates concerns (sensing, actuation,
communication, coordination), the implementation assumptions make it unsuitable
for disaster-resilient systems where edge servers may be the infrastructure
that fails. The formal guarantees of self-stabilization and compositional
properties come at the cost of persistent computational infrastructure that an
embedded-focused deployment cannot provide.

\subsection{MicroBabel's Approach}
\label{subsec:microbabel_approach_2}

Tree topologies and coordinator-based approaches limit resilience, and
heavyweight middleware platforms or HyParView's TCP requirements exceed
embedded device capabilities.

\textbf{MicroBabel} intends to address these limitations through a fully
distributed peer-to-peer mesh architecture without coordinator dependencies.
The system adapts HyParView's hybrid view concept (maintaining small active
neighbor sets for actual communication and larger passive backup lists for
failure recovery) but implements discovery and maintenance using
\inlinetodo{BLE, LoRa...?} rather than TCP connections, accommodating the
connectionless nature of embedded radio/wireless communication.

Neighbor discovery combines \inlinetodo{BLE, LoRa...?} advertising beacons
(carrying node identity, capabilities, and current neighbor counts, \inlinetodo{mais coisas?}) with
periodic gossip exchanges that propagate topology information beyond single-hop
radio range.

This multi-mechanism approach mitigates potential range limitations: while BLE
typically provides 10-50m coverage depending on environment and antenna
configuration, gossip-based propagation enables nodes to learn about distant
neighbors through multi-hop dissemination, supporting informed routing
decisions and topology adaptation.

Unlike the tree topology of Multi-Protocol Gateway or the RPL DODAG structure
of heterogeneous disaster architecture, \textbf{MicroBabel} will implement true
peer-to-peer mesh networking where any node can communicate with any other node
through dynamically selected multi-hop paths.

Route selection considers multiple factors gathered through local observation
and gossip: link quality metrics (RSSI, packet success rates), neighbor
availability across different protocols, and current energy budgets.

Store-and-forward mechanisms inspired by Bundle Protocol will enable operation
during network partitions, but will be adapted for peer-to-peer rather than
cloud-centric operation: data parcels are compressed (using techniques from
Section~\ref{sec:data_compression}), queued in local storage (flash, MicroSD
cards) when no forward path exists, and opportunistically transmitted when
connectivity windows emerge, be it through topology changes or protocol
switching creating new communication opportunities.

Coordination emerges from local interactions via gossip-based information
propagation, decentralized time synchronization
(Section~\ref{sec:decentr_sync}), and adaptive protocol selection
(Section~\ref{sec:multi-proto}), rather than centralized allocation of roles.

\section{Decentralized Synchronization and Time Coordination}
\label{sec:decentr_sync}

Multi-channel communication strategies, particularly those that employ
coordinated channel hopping for security or efficiency reasons, require nodes
to maintain synchronized clocks. Without time synchronization, devices cannot
agree on when to switch channels, rendering coordinated multi-protocol
operation impossible.

Traditional master-based synchronization approaches -- where a designated
coordinator is responsible for communicating timing signals -- once more fall
into the trap of having a single point of failure in that same master node:
should it fail, the entire network becomes susceptible to losing accurate
temporal reference, leading to the collapse of any coordination efforts.

This is a notorious challenge to overcome when designing distributed systems,
and it becomes more prominent in the disaster scenarios discussed thus far,
where infrastructure failures are likely to eliminate the nodes responsible for
time synchronization in a given system.

Achieving robust time synchronization in such situations requires fully
decentralized approaches that eliminate central coordinator dependencies while
still remaining sufficiently lightweight to be executed on resource-constrained
platforms.

\subsection{Master-Based Synchronization as Counterexample}
\label{subsec:master_sync}

As discussed in Section~\ref{subsec:multi-channel}, the MCSC-WoT
framework~\cite{mcsc-wot} demonstrates a security-focused multi-channel hopping
approach aimed at embedded platforms, but with a fundamental dependency on a
master node broadcasting synchronization signals.

This approach uses a shared PRNG seed to generate channel-hopping sequences,
with the master node broadcasting periodic synchronization beacons that slave
nodes use to compensate for clock drift. Nodes that lose synchronization
altogether can rejoin by hopping to a random channel and waiting for the next
master beacon.

While the proposed goals were achieved in terms of minimizing energy
expenditure and maintaining FHSS patterns, it inherits the fundamental
limitation of all master-based approaches mentioned at the start of
Section~\ref{sec:decentr_sync}. If the master fails or becomes unreachable,
participating nodes gradually drift out of synchronization until coordinated
channel hopping is no longer possible.

The system's clock drift compensation algorithm demonstrates the feasibility of
synchronization on ESP32 platforms, and their measured AES encryption
performance validates that lightweight security can coexist with time
synchronization on resource-constrained devices. However, the architectural
dependency on a central coordinator fundamentally conflicts with
infrastructure-independent operation requirements we aim to fulfill.

\subsection{Gossip-Based Masterless Synchronization}
\label{subsec:gossip_sync}

Decentralized time synchronization eliminates coordinator dependencies by
having nodes reach consensus on clock values through distributed local
interactions. Two complementary approaches demonstrate the viability of
gossip-based synchronization for wireless sensor networks.\todo{mau usar WSN aqui?}

The randomized gossip-consensus-based sync (RGCS) algorithm proposed
in~\cite{rgcs2018} addresses time synchronization in dynamic WSNs through
randomized asynchronous gossip. Each node maintains a logical clock (T)
composed of rate ($\alpha$) and offset ($\beta$) parameters, which together transform the
node's hardware clock ($\tau$) into synchronized logical time.

Rather than requiring fixed communication links between specific node pairs
which might be fragile in dynamic topologies, their approach uses Poisson-based
randomized link activation where each potential synchronization link activates
with intensity $\lambda$.

The synchronization process operates through pairwise gossip exchanges: when a
link activates, the triggering node sends a Sync-L beacon selecting a triggered
neighbor, followed by bidirectional exchange of multivariable messages
containing each node's current logical clock parameters [$\alpha, \beta, \tau$].

The asynchronous randomized timing of these exchanges is advantageous in that
collision rates drop to near zero compared to 19-23\% for deterministic
communication protocols, as independent Poisson intervals make simultaneous
transmissions to the same receiver statistically unlikely.

The proposed RGCS employs a converge-to-max criterion rather than average-value
consensus. This maximum-based approach achieves finite time convergence
significantly faster than average-based protocols that require many iterations
to converge under significant clock drift. Offset compensation follows suit,
with nodes adjusting $\beta$ parameters based on the difference between their
and the neighbors' logical clocks.

Bounded communication delays are handled through a least-square estimation
low-pass filter.\todo{não sei se sei explicar este low-pass filter, vale a
pena?} This addresses the realistic concern of uplink and downlink delays
differing, and avoids the symmetric delay assumptions made by many theoretical
protocols. The filter's weighing parameter decreases over time, in order to
restrain the negative effects of additive noise in stochastic approximation.

Storage complexity remains O($|N_i|$) per node per iteration (proportional only
to the number of neighbors, not network size) thus ensuring scalability. The
protocol simultaneously compensates both clock rate and offset, unlike
approaches that handle these separately and thus require additional convergence
time.

\subsection{Coordination Through Passive View Maintenance}
\label{subsec:coord_passive}

As discussed in Section~\ref{subsec:peer_disc}, the shuffle-based passive view
maintenance presented in HyParView~\cite{hyparview2007} provides a
complementary coordination mechanism. While primarily designed for topology
management, the periodic shuffle operations in which nodes exchange lists of
known peers can also serve the purpose of propagating network membership
information that can inform synchronization decisions.

Nodes performing shuffle exchanges already communicate periodically; these same
communication windows can opportunistically carry synchronization messages,
reducing protocol overhead. The passive view serves as a pool of potential sync
partners, so that when a node's active sync neighbors become unreachable, it
can initiate sync exchanges with passive view members, providing added
resilience to topology changes without requiring global network knowledge.

\subsection{MicroBabel's Approach}
\label{subsec:microbabel_approach_3}

While MCSC-WoT demonstrates master-based synchronization feasibility and RGCS
provides masterless convergence, both assume homogeneous single-protocol
networks.

\textbf{MicroBabel} will extend RGCS to heterogeneous multi-protocol networks
through protocol-specific Poisson processes with distinct activation rates.
Rather than a single $\lambda$ controlling overall sync frequency, the system
employs per-protocol gossip rates that take into account the energy required
for each transmission, and the current network conditions:

\todo{does this make sense para o que queremos?}

\begin{description}
    \item \textbf{$\lambda$\_BLE} (high frequency): provides rapid local
        synchronization with nearby neighbors, leveraging BLE's low energy cost
        for frequent exchanges
    \item \textbf{$\lambda$\_LoRa} (low frequency): maintains long-range
        temporal coordination, using LoRa's more expensive transmissions
        sparingly
    \item \textbf{$\lambda$\_Wi-Fi} / Others (medium frequency): situational
        use based on network density, energy budgets and other factors
\end{description}

Each protocol will have its own Poisson-triggered gossip loop, but all updates
contribute to a single shared logical clock via the converge-to-max criterion
explored above. When sync events from different protocols occur
near-simultaneously, the max operation's associativity ensures correct
convergence regardless of update order.

This multi-graph gossip approach provides several advantages over homogeneous
sync:
\begin{description}
    \item \textbf{Faster convergence:} High-frequency BLE gossip can achieve
        tighter local consensus while sparse LoRa exchanges prevent drift
        between distant clusters. The combination converges faster than either
        protocol alone.
    \item \textbf{Resilience through diversity:} If 2.4 GHz interference
        disrupts BLE/Wi-Fi synchronization, LoRa maintains loose temporal
        coordination across the network. Conversely, if LoRa experiences poor
        conditions, local BLE sync keeps nearby nodes coordinated.
    \item \textbf{Natural energy optimization:} Protocol characteristics
        directly inform sync frequencies, so that more expensive long-range
        transmissions occur rarely while cheap short-range exchanges happen
        frequently, matching energy budgets to communication needs.
\end{description}

Hysteresis control mechanisms adapted from Section~\ref{sec:multi-proto} will
prevent oscillations in protocol selection during sync events: sync partner and
protocol choices stabilize around locally optimal configurations rather than
continuously switching between equally-viable options.

The approach aims to handle network partitions gracefully: nodes maintain
synchronization within their reachable partition using available protocols, and
when partitions merge (through mobility or topology changes), the
converge-to-max criterion naturally reconciles previously independent temporal
references without requiring special merge logic.

Unlike MCSC-WoT's master-based approach, this architecture will operate in a
fully peer-to-peer fashion with no fixed coordinator dependencies. The
multi-protocol extension goes beyond RGCS's original homogeneous network
assumptions, since heterogeneous gossip graphs with protocol-specific
characteristics warrant distinct sync frequencies, enabling simultaneous
optimization of convergence speed, energy consumption, and range coverage.

\section{Lightweight Data Compression and Energy Efficiency}
\label{sec:data_compression}

Energy constraints present one of the most fundamental limitations in
battery-powered IoT deployments, particularly in hazardous deployments where
replacements and recharging are impractical, and during disaster scenarios
where grid power likely becomes unavailable.

While multi-protocol communication and decentralized coordination efforts
provide resilience, they also introduce increased energy costs through frequent
transmissions, protocol adaptation overhead and forwarding costs.

Data transmission dominates energy consumption across wireless technologies:
LoRa and SIGFOX can represent up to 99.9\% of power consumption for
transmission, while even shorter-range technologies like BLE and IEEE 802.15.4
dedicate 85-90\% of their energy budget to radio
operations~\cite{ambrosia2021}.

This reality makes data reduction techniques essential for extending
operational lifetime in infrastructure-independent scenarios. However,
compression itself consumes energy through additional computational work, thus
creating an unavoidable tug-of-war between compression overhead and
transmission benefits.

\subsection{Prediction-Based Data Reduction}
\label{subsec:prediction_reduction}

The Ambrosia protocol~\cite{ambrosia2021} demonstrates that lightweight
prediction can achieve substantial data reductions on resource-constrained
devices. The core idea is that not all sensor readings need to be transmitted
if their values can be accurately predicted at the server (within the bounds
of a specified error threshold), provided that both sender and receiver
maintain a synchronized "prediction state".

Their approach uses window-based forecasting where the next sample is predicted
by adding the average differences between recent previous samples, making it
dramatically lighter than sophisticated time-series forecasting techniques
like ARIMA~\cite{arima2017} while still achieving comparable data reduction
performance.

The protocol works by sending the first \emph{w} (window size) true samples
collected by the sensor node to the server, and for every sample after that
comparing its true value to the one predicted locally; the true sample value is
sent to the server only if the absolute difference between it and the prediction
is greater than a user or application-specified error threshold $\delta$.

The same simple prediction scheme is used on both ends of this communication,
and the predicted value is the one used for further predictions -- even on the
sensor node that knows the true value, to ensure consistency between the two
endpoints.

This design achieves up to 60\% data reduction with appropriate $\delta$
configuration while maintaining sufficient accuracy for diverse applications:
for error-tolerant use cases like anomaly detection, $\delta$ values will be
higher to allow for reasonable fluctuations, thus enabling more significant
data reductions, while error-sensitive applications requiring higher precision
will naturally lean towards stricter error thresholds, but still benefitting
from some amount of data reduction.

The major takeaway from this work is that the window-based prediction executed
99\% faster than ARIMA forecasting in their evaluation, making it viable for
streaming sensor data at high rates. The approach achieved 2$\times$ battery
lifetime improvement in high-traffic scenarios and demonstrated compatibility
with extremely constrained devices (livestock ear tags with Atmel 8-bit
microcontrollers).

\subsection{Lightweight Compression}
\label{subsec:lightweight_compression}

While prediction-based reduction minimizes the number of transmissions,
compression techniques are essential to reduce the size of the data that
\emph{must} be transmitted.

A few complementary approaches address different considerations and
constraints: hybrid schemes balance accuracy with transmission costs through
lossy/lossless models; lossless time-series compression exploits the natural
temporal relation in continuous sensor readings; and two-tier architectures
apply different techniques at both the sensor and gateway level to reduce
energy costs.

\subsubsection*{Hybrid Lossy/Lossless Compression}

The hybrid compression scheme presented in~\cite{hybrid2017} addresses accuracy
requirements by separating real-time lossy transmission from on-demand lossless
reconstruction. The Fan algorithm adaptively sub-samples data maintaining
bounded error $\varepsilon$, achieving average 7.8$\times$ and 2.1$\times$
compression ratio (CR) for lossy and lossless compression, respectively.

The approach provides graceful degradation through battery-aware switching, in
that when battery drops below a certain threshold (e.g., 20\%), the system
switches to lossy-only transmission instead of lossless, extending lifetime at
the cost of reconstruction accuracy.

\inlinetodo{add more detail here but need to read it more carefully}

\subsubsection*{Lossless Time-Series Compression}

Sprintz~\cite{sprintz2018} targets lossless compression for multivariate
integer time-series with extreme resource constraints, achieving 2-10$\times$
compression ratios with <1KB memory footprint and 8-sample block sizes. The
four-component algorithm combines forecasting (delta coding or FIRE (Fast
Integer REgression) online learning), bit packing with zigzag encoding, RLE
(run-length encoding) for all-zero blocks, and optional Huffman coding.

Delta coding is extremely fast, and when combined with RLE becomes even more
so, as it yields a run of zero errors if the data is constant, which is likely
to happen for nominal sensor readings. FIRE forecasting yields better
compression, but its online learning approach place it beyond the scope of
this paper.

A \emph{forescaster} is employed to predict each sample based on previous ones,
and the difference between the next and the predicted sample are encoded. This
difference is typically closer to zero than the next sample itself.

Any prediction errors from the previous forecasting step are zigzag
encoded~\inlinetodo{add citation here or not really necessary?} as a "payload",
and a header is prepended with sufficient information to invert the bit
packing.

If a block happens to consist only of zeros, this approach waits for a block in
which there is a non-zero error, and the number of all-zero blocks are written
out using RLE instead of the (empty) payload.

Finally, the bit packed representation of each block can be \emph{entropy
coded} using a Huffman coder, applied to the headers and payloads. This is done
after bit packing because not only is it faster, but it also increases
compression.

Decompression can achieve up to 3GB/s throughput without Huffman coding
(>500MB/s with Huffman) in a single thread, enabling high-speed data retrieval
on gateway-tier devices. Compression maintains >200MB/s on 8-bit data,
sufficient for real-time operation even on embedded platforms.

\subsubsection*{Two-Tier Compression Architecture}

The two-tier data reduction (TTDR) technique proposed in~\cite{twotier2019}
applies compression at both sensor nodes (Tier 1) and gateways (Tier 2) to
reduce energy consumption in the overall system.

Sensor nodes employ Delta encoding followed by RLE, allowing this approach to
achieve 80-84\% compression by exploiting the temporal correlation in sensor
data. Gateways perform hierarchical clustering based on the Minimum Description
Length (MDL) principle, transmitting \emph{hypothesis} data sets and
difference vectors instead of full data sets.

\todo{falar mais do MDL ou como é gateway side not so important?}

The Delta+RLE implementation -- validated through OMNeT++ simulation -- proves
to be lightweight enough for resource-constrained nodes, while gateway
clustering reduces transmission to cloud infrastructure.

\subsection{Receiver-Side Energy Considerations}
\label{subsec:receiver_energy}

An oft-overlooked aspect of IoT energy optimization is the asymmetry between
sender and receiver energy consumption. The adaptive protocol selection
framework analysis~\cite{adaptive2025} revealed that receiver nodes
consistently consume 15-20\% more energy than senders across all evaluated
protocols (MQTT, CoAP, HTTP).

This asymmetry shifts the energy bottleneck from endpoint sensors to
intermediary nodes like gateways and has direct implications for gateway power
management in disaster scenarios where battery replacement becomes impossible.
The increased receiver cost stems from the added computational work required
for parsing, processing, and managing incoming messages, particularly at high
message rates.

For \textbf{MicroBabel}'s proposed two-tier architecture where sensor nodes
might eventually forward data to aggregators/gateways, this finding has direct
implications in that managing the power consumption of these gateways becomes
as significant as sensor power optimization, since one gateway might receive
substantial data from several nodes even if individually they don't perform
frequent transmissions.

\subsection{MicroBabel's Approach}
\label{subsec:microbabel_approach_4}

Extending Ambrosia's lightweight prediction approach to multi-protocol
scenarios, \textbf{MicroBabel} will reduce data transmission through
prediction-based filtering: nodes transmit sensor readings only when prediction
error exceeds configurable thresholds (similar to Ambrosia), with
protocol-aware tuning to balance accuracy against energy constraints across
heterogeneous protocols.

Building on prediction-based reduction, the goal is to apply Delta+RLE compression
to the readings that are transmitted, combining both techniques for added
energy savings and reduced data volume over the air.

Following the two-tier architecture pattern, compression occurs at sensor nodes
before transmission, with just the first sample in each window being
transmitted with no compression applied.

Adaptive threshold selection will adjust $\delta$ based on both channel
characteristics and node state:
\todo{estes deltas vinham do ambrosia, fica confuso agora que falo de delta encoding?}
\begin{itemize}
    \item \textbf{High $\delta$ for LoRa}: Tolerates larger prediction errors
        to minimize expensive long-range transmissions, sending only when
        predictions deviate significantly. These packets undergo
        aggressive Delta+RLE compression to minimize airtime costs.
    \item \textbf{Low $\delta$ for BLE}: Requires tighter prediction accuracy
        for cheap local exchanges, allowing for more frequent transmissions to
        maintain precision. Lighter compression (delta encoding only) 
        is applied here for lower latency.
    \item \textbf{Battery-aware adaptation}: As node energy depletes, increased
        $\delta$ across all channels reduces transmission frequency, extending
        lifetime for critical messages. Compression at this point becomes more
        lossy to further minimize transmitted data volume.
\end{itemize}

\textbf{Application-aware transmission} will distinguish between data types:
periodic sensor readings (temperature, humidity, light) use window-based
prediction with configurable $\delta$ thresholds, while discrete events
(emergency alerts, button presses, motion detection) transmit immediately
without prediction. For predictable streams, accuracy-critical applications
maintain low $\delta$, while trend monitoring can accept higher values to
reduce transmission frequency.

Compression strategies also vary by data type: environmental sensors can
tolerate more prominent Delta+RLE compression given their high temporal
correlation, while critical alerts transmit with minimal (if any) compression
to reduce latency.

\textbf{Gateway energy management} accounts for the 15-20\% receiver energy
cost by implementing selective radio shutdown: gateways can disable specific
protocols during low-activity periods, waking periodically to check for
incoming sync beacons or when prompted via other protocols. Decompression
overhead in these nodes is minimal compared to transmission costs at
the sensor level.
\todo{entrar pela coisa de desligar os rádios ainda mais?}

The expectation is that the combination of lightweight prediction, adaptive
thresholding, and protocol-specific tuning together with Delta+RLE compression
will provide substantial energy savings without requiring complex and
computationally intensive compression algorithms that would themselves consume
significant power.

\section{Security and Privacy for Resource-Constrained Emergency Communication}
\label{sec:sec_priv}

Disaster scenarios inherently involve sensitive data, such as location tracking
for search-and-rescue operations, environmental conditions for risk assessment,
among many others.

Unlike conventional IoT deployments where security infrastructure can be
carefully provisioned, emergency-focused deployments must balance security
guarantees against the possibility of infrastructure failure.

Traditional security approaches that assume persistent connectivity to
Certificate Authorities (CAs), Key Distribution Centers (KDCs), or even
blockchain networks cannot fully function, if at all, when those very
structures collapse. Embedded platforms further exacerbate this issue by ruling
out computationally expensive cryptographic approaches that could more easily
provide a given network with a certain degree of independence from those
structures.

\subsection{Lightweight Encryption on Embedded Platforms}
\label{subsec:lightweight_enc}

The MCSC-WoT framework~\cite{mcsc-wot} demonstrates that AES encryption can
operate efficiently on ESP32 platforms while maintaining multi-channel
communication. Their implementation combines AES encryption with dynamic
channel hopping, using a PRNG-based sequence to coordinate channel switches
across devices.

The measured encryption overhead validates that symmetric cryptography remains
viable on resource-constrained devices, though their approach assumes a shared
PRNG seed can be distributed during an initial deployment phase.

While suitable for scenarios where controlled deployment precedes operation,
the master-based synchronization also reintroduces coordinator dependencies
that conflict with infrastructure-independent operation requirements, as
previously noted.

\subsection{Distributed Key Management}
\label{subsec:distrib_key_man}

The challenge of establishing shared cryptographic keys across resource-
constrained devices without central coordination has received substantial
attention, though most approaches make assumptions incompatible with disaster
scenarios.

\subsubsection*{Polynomial-Based Key Management}

The LPKM (Lightweight Polynomial-based Key Management) protocol~\cite{lpkm2013}
provides a compelling foundation for embedded key distribution. Using
polynomial evaluation on 8MHz ATmega128L microcontrollers, this approach
generates 128-bit group keys in 2-16 milliseconds with storage requirements of
only 496-1616 bytes (depending on security parameter $k$).

The proposed scheme supports multiple key types within a unified framework:
pairwise keys between (non-)neighboring nodes, cluster keys for local groups,
and group keys for larger networks. Storage complexity is O($k+1$) coefficients
per node, independent of network or group size, ensuring scalability.

No less critical for disaster scenarios -- where the possibility of malicious
agents must still be taken into account -- LPKM enables distributed revocation
without central coordination. When a node is compromised, legitimate nodes can
independently compute updated keys that exclude the revoked member, with no
re-keying delay or coordinator involvement. Periodic share updating provides
backward secrecy through timer-based refresh operations that require no
coordination.

This approach does assume secure bootstrapping via a KDC that preloads
polynomial shares into devices before deployment. For planned
disaster-resilience installations (\inlinetodo{campus thing?}), this physical
preloading is acceptable. For rapid deployment during emergencies, a trusted
device (laptop, PDA, etc.) can serve as a temporary KDC to provision newly
added nodes.

\subsubsection*{Zero-Preloading Approaches}

Alternative schemes attempt to eliminate pre-distributed keys entirely. The
lightweight distributed key agreement protocol presented in
~\cite{lightweight2008} achieves a considerable speedup compared to
Diffie-Hellman by employing hash functions and bit-wise comparisons rather
than modular exponentiation.

The approach generates temporal key pairs on-demand through random secret
number generation, with nodes deriving shared keys via hash-based operations
and bit-wise comparisons of prefix bit-strings, thus eliminating the need for
pre-distributed keys.

However, it requires an inter-sensor authentication protocol to secure the
initial public key exchange, creating a circular dependency: authentication
requires keys, but key establishment requires authentication. Furthermore,
revocation mechanisms are only briefly mentioned without any concrete details,
limiting the potential of this implementation.

This highlights a fundamental pressure point in zero-config security:
establishing trust without pre-shared secrets or trusted third parties.

\subsection{Authentication and Privacy}
\label{subsec:authentication_privacy}

-- TODO TODO TODO TODO --

\subsection{Centralized Security Approaches (Incompatible with Disasters)}
\label{subsec:centr_sec}

Several recent approaches leverage blockchain or centralized infrastructure to 
solve IoT security challenges, but their dependencies render them unsuitable 
for disaster scenarios.

The blockchain-based access control system in~\cite{towards2019} moves Policy
Decision Points onto distributed ledgers, eliminating single points of failure
in access control. However, it assumes continuous connectivity to blockchain
nodes and cloud storage for off-chain data, failing precisely when
infrastructure collapses.

Similarly, the decentralized PKI approach using blockchain-based Name/Value
Storage~\cite{decentralized2018pki} replaces Certificate Authorities with
distributed blockchain nodes. While removing central CA dependencies, it still
requires Internet connectivity for NVS queries and assumes blockchain nodes
remain reachable, which invalidates their usage during disasters.

Decentralized attribute-based encryption (ABE) schemes~\cite{privacy2012}
eliminate central authorities through multi-authority cryptography but rely on
bilinear pairings with computational costs far exceeding the capabilities
of our targeted platforms.

\subsection{MicroBabel's Approach}
\label{subsec:microbabel_approach_5}

LPKM provides lightweight key management but requires initial KDC provisioning,
while zero-config approaches face circular authentication dependencies and
centralized schemes fail when infrastructure collapses.

\textbf{MicroBabel} will adopt a hybrid security model that distinguishes 
between pre-disaster deployment and post-disaster autonomous operation.

\begin{description}
    \item \textbf{Pre-disaster deployment phase:} For planned installations
        (building sensor networks, campus-wide monitoring), polynomial shares
        will be preloaded via KDC during initial deployment.

        These are reasonable assumptions for disaster-resilience scenarios, as
        preparation happens before any emergency operation needs to take place.

    \item \textbf{Post-disaster autonomous operation:} Once a disaster occurs
        and infrastructure fails, the network operates autonomously using
        mechanisms that require no central coordination:

        \begin{itemize}
            \item \textbf{Distributed revocation} (adapted from LPKM): nodes
                independently compute updated keys excluding compromised peers,
                with revocation decisions propagated via gossip
            \item \textbf{Periodic share updating} (adapted from LPKM):
                timer-based key refresh for backward secrecy, no coordinator
                needed
            \item \textbf{Lightweight encryption}: AES encryption (demonstrated
                by MCSC-WoT on ESP32) with compress-then-encrypt
                strategies~\ref{sec:data_compression} to minimize ciphertext
                size and transmission energy
            \item \textbf{Channel hopping/protocol switching for security}:
                multi-channel/multi-protocol operation complicates
                eavesdropping and uses masterless synchronization
                (RGCS) rather than master-based beacons
        \end{itemize}
    
    \item \textbf{Threat model:} The system will prioritize availability and
        resilience over complete compromise resistance. Assumptions include:

        \begin{itemize}
            \item \textbf{Honest majority}: most nodes behave correctly;
                adversaries cannot compromise majority simultaneously
            \item \textbf{Local adversary}: attackers can monitor/disrupt local
                regions but not entire network simultaneously
            \item \textbf{Physical security during deployment}: devices can be
                provisioned securely before disaster strikes
        \end{itemize}

        This threat model reflects emergency priorities where maintaining
        communication capability matters more than preventing all possible
        attacks. If an adversary with sophisticated capabilities attacks during
        a disaster, communication infrastructure would already be their target
        regardless of security mechanisms.
\end{description}

\todo{ainda me falta a tabela mas só no final caso tenha de cortar algum paper}
